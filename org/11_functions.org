#+TITLE: Writing your own functions
#+AUTHOR: Marcus Birkenkrahe (pledged)
#+SUBTITLE: DSC 205 - Advanced introduction to data science
#+STARTUP: overview hideblocks indent inlineimages entitiespretty
#+OPTIONS: toc:nil num:nil ^:nil
#+PROPERTY: header-args:R :session *R* :results output :exports both :noweb yes
* README

- In this review, we'll explore why to write your own functions in R
  with examples.

- You'll implement these from pseudocode to practice translating logic
  into code.

- Inspired by DataCamp lesson "Introduction to Writing Functions in
  R", written and tested with AI assistance (Grok 3 beta version).

- Codealong file: [[https://tinyurl.com/functions-codealong][tinyurl.com/r-functions-codealong]]

* New Functionality: Calculate Midrange

Sometimes R lacks a specific tool you need. The midrange—average of
the maximum and minimum values—is a simple measure of central tendency
not built into base R.

- *Task*: Write a function ~calc_midrange~ that takes a numeric vector and
  returns its midrange =(max + min) / 2=.

- *Test Case*: Use =[5, 8, 3, 10, 6]= (should output =6.5=).

*Where It’s Used*: In statistics, midrange is a quick estimate of a
dataset’s center, like =[20, 25, 30]= for temperatures. It’s niche but
useful in exploratory analysis when ~median~ or ~mean~ isn’t ideal.

*Pseudocode:*

#+BEGIN_EXAMPLE
FUNCTION calc_midrange takes a numeric vector x
  SET max_val to the maximum of x (handle missing values)
  SET min_val to the minimum of x (handle missing values)
  COMPUTE midrange as (max_val + min_val) / 2
  RETURN midrange
END FUNCTION
#+END_EXAMPLE

*Challenge:*
- Turn the function into a one-liner =calc_midrange2=.
- Which function is faster? (We'll compute that next.)

** Sample solutions

- Long solution:
  #+begin_src R :session *R* :results none :exports both
    ## FUNCTION calc_midrange takes a numeric vector x
    calc_midrange <- function(x) {
      ## SET max_val to the maximum of x (handle missing values)
      max_val <- max(x, na.rm=TRUE)
      ## SET min_val to the minimum of x (handle missing values)
      min_val <- min(x, na.rm=TRUE)
      ## COMPUTE midrange as (max_val + min_val) / 2
      midrange <- (max_val + min_val)/2
      ## RETURN midrange
      return (midrange)
    } # END FUNCTION
  #+end_src

- Test:
  #+begin_src R :session *R* :results output :exports both
    foo <- c(5, 8, 3, 10, 6)
    calc_midrange(foo)
  #+end_src

  #+RESULTS:
  : [1] 6.5

- *Challenge*: Short solution (no intermediate objects)
  #+begin_src R :session *R* :results output :exports both
    ## FUNCTION calc_midrange takes a numeric vector x
    calc_midrange2 <- function(x) {
      (max(x, na.rm=TRUE) + min(x, na.rm=TRUE)) / 2
    }
    bar <- c(5, 8, 3, 10, 6)
    calc_midrange2(bar)
  #+end_src

  #+RESULTS:
  : [1] 6.5

- Are there arguments for or against the short solution?
  #+begin_quote
  + *Con:* It is less readable and hence less debuggable.
  + *Pro:* It has a slightly smaller computational overhead.
  #+end_quote

- What if one wanted to re-use =max_val= and =min_val= from the long
  solution?
  #+begin_quote
  These objects are local to the function, and they cannot be accessed
  outside. You'd have to return them as part of a list to retain them,
  or use the ~<<-~ operator or the ~assign~ function.
  #+end_quote

- Demonstration of ~<<-~
  #+begin_src R :session *R* :results output :exports both
    rm(list=ls()) # clean environment from user-defined stuff
    ## Define function
    f <- function() { 
      global <<- 100    # add to .GlobalEnv
      non_global <- 200
    }

    f() # call function
    global # print variable
    ls(envir=.GlobalEnv)
    non_global # local variable
  #+end_src

  #+RESULTS:
  : [1] 100
  : [1] "f"      "global"
  : Error: object 'non_global' not found

* Comparing Function Performance

Let’s explore how function design affects speed. Below are two
versions of the midrange function—your task is to measure which is
faster and explain why.

- *Task:* Benchmark Two Midrange Functions. Here are two functions that
  calculate the midrange (average of max and min):
  #+name: f1
  #+BEGIN_SRC R
    calc_midrange <- function(x) {
      max_val <- max(x, na.rm=TRUE)
      min_val <- min(x, na.rm=TRUE)
      midrange <- (max_val + min_val)/2
      return(midrange)
    }
  #+END_SRC

  #+RESULTS: f1

  #+name: f2
  #+BEGIN_SRC R
    calc_midrange2 <- function(x) {
      (max(x, na.rm=TRUE) + min(x, na.rm=TRUE)) / 2
    }
  #+END_SRC

  #+RESULTS: f2

- *Goal*: Use R to measure which function runs faster on a small and
  large dataset.

- *Steps*:
  1. Install and Load the ~microbenchmark~ package.
  2. Create a small vector and a large vector.
  3. Use ~microbenchmark()~ to compare the functions, running each at
     least 100 times.
  4. Report the ~median~ times for both functions on both datasets.

- *Test Cases*:
  - Small: =[5, 8, 3, 10, 6]= 
  - Large: =rnorm(10000)= (random normal data)

- *Where It’s Used*: In data science, performance matters when
  processing big datasets (e.g., millions of sensor readings). Small
  efficiency gains in functions can add up.

** Sample Solution (with extension)

1. Load the ~microbenchmark~ package (install if needed:
   ~install.packages("microbenchmark")~).
   #+begin_src R :session *R* :results output :exports both
     install.packages("microbenchmark")
     library(microbenchmark)
   #+end_src

   #+RESULTS:

   Check that it's been loaded.
   #+begin_src R :session *R* :results output :exports both
     search()[grep("microbenchmark",search())]
   #+end_src

   #+RESULTS:
   : [1] "package:microbenchmark"

   We need this search more often, so let's turn the last command into
   a function using ~grep~, which returns an index:
   #+begin_src R :session *R* :results output :exports both
     grep("micro",search())
   #+end_src

   #+RESULTS:
   : [1] 2

   Now the function:   
   #+begin_src R :session *R* :results output :exports both
     loaded <- function(str) {
       search()[grep(str,search())] # grep returns an index
     }
     loaded("microbenchmark")
   #+end_src

   #+RESULTS:
   : [1] "package:microbenchmark"

   To not have to recreate and/or reload this useful function, you
   need to save it and have it be loaded automatically by R, using
   ~dump~. You can check the result with ~system~ (or ~shell~ on Windows):
   #+begin_src R :session *R* :results output :exports both
     dump("loaded",file="~/my_functions.R") # dump code to file
     system("cat ~/my_functions.R") # view dumped file
   #+end_src

   #+RESULTS:
   : loaded <-
   : function(str) {
   :   search()[grep(str,search())] # grep returns an index
   : }

   To load when R starts up, add =source(~/my_functions.R)= to your
   =~/.Rprofile= file. You can test that by opening a new R console, and
   checking with =ls()=, then with =loaded("base")= to see if it worked.

   My =~/.Rprofile= file:
   #+begin_example R
   options(repos=c("https://mirrors.nics.utk.edu/cran/"))
   options(crayon.enabled = FALSE)
   options(prompt="> ")
   source("~/my_functions.R")
   message("*** Loaded .Rprofile ***")
   #+end_example

2. Create a small vector (e.g., 5 numbers) and a large vector (e.g.,
   10,000 numbers with ~rnorm()~).

   #+begin_src R :session *R* :results output :exports both
     small_data <- c(5, 8, 3, 10, 6)
     large_data <- rnorm(10000)
     head(large_data)
   #+end_src

   #+RESULTS:
   : [1]  0.27222347  0.59617239 -1.65685604  1.52222266 -0.01147845 -0.02731232

3. Use ~microbenchmark()~ to compare the functions, running each at
   least 100 times.

   #+begin_src R :session *R* :results output :exports both
     args(microbenchmark)
   #+end_src

   #+RESULTS:
   : function (..., list = NULL, times = 100L, unit = NULL, check = NULL, 
   :     control = list(), setup = NULL) 
   : NULL

   #+begin_src R :session *R* :results output :exports both
     microbenchmark(calc_midrange(small_data),calc_midrange2(small_data),times=100)
     microbenchmark(calc_midrange(large_data),calc_midrange2(large_data),times=100)
   #+end_src

   #+RESULTS:
   : Unit: nanoseconds
   :                        expr min    lq     mean median    uq     max neval
   :   calc_midrange(small_data) 375 393.0 69679.44  407.0 462.0 6919235   100
   :  calc_midrange2(small_data) 301 314.5  8209.79  334.5 386.5  785019   100
   : Unit: microseconds
   :                        expr   min     lq     mean  median      uq    max neval
   :   calc_midrange(large_data) 14.88 14.912 15.08845 14.9285 14.9730 27.747   100
   :  calc_midrange2(large_data) 14.81 14.842 14.89869 14.8555 14.8715 16.947   100

4. Report the median times for both functions on both datasets.

   - Small data (5 data points): Nanoseconds: [ns] = one billionth of
     a second (E-09)
     + ~calc_midrange~: Median = 554.18 ns
     + ~calc_midrange2~: Median = 445.84 ns
     + Difference: 88.5 ns faster for ~calc_midrange2~.

   - Large data (10,000 data points): Microseconds: [µs] = millionth
     of a second (E-06)
     + ~calc_midrange~: Median = 14.930 µs
     + ~calc_midrange2~: Median = 14.864 µs
     + Difference: 0.12 µs faster for ~calc_midrange2~.

   - *Which is Faster?*
     + ~calc_midrange2~ wins in both cases—79 ns faster for small data,
       0.108 µs for large data.
     + Why? It skips variable assignments and ~return~, reducing
       overhead.

   - *Why the Difference?*
     + Small data: Extra steps in ~calc_midrange~ (three assignments)
       add ~16% to its time.
     + Large data: ~max()~ and ~min()~ take most of the time, so the
       overhead is tiny (<0.2%).

- *Does It Matter?* For small data, 79 ns is too small to notice unless
  called billions of data.

* Converting scripts to functions

- The process:
  #+begin_quote
  1. Make a template
  2. Paste in the script
  3. Choose the arguments
  4. Replace specific values with argument names
  5. Make specific variable names more general
  6. Remove a final assignment
  #+end_quote

- Can you do this for the following script? It calculates the
  percentage of values in a dataset above a specific threshold,
  e.g. test scores above 70:
  #+begin_src R :session *R* :results output :exports both
    ## Calculate percentage of values above threshold
    scores <- c(65, 78, 92, 55, 88)
    threshold <- 70
    count_above <- sum(scores > threshold)
    total <- length(scores)
    percent_above <- (count_above / total) * 100
    percent_above
  #+end_src

  #+RESULTS:
  : [1] 60

- It works for only one specific case - for the given vector =scores=,
  =60%= of the values are above =70=. Generalize it as a function now!

** Sample Solution

- Steps:

  1. Make a template:
     #+begin_src R :session *R* :results none
       percent_above <- function() {
       }
     #+end_src

  2. Paste in the script
     #+begin_src R :session *R* :results none
       percent_above <- function() {
         ## Calculate percentage of values above threshold
         scores <- c(65, 78, 92, 55, 88)
         threshold <- 70
         count_above <- sum(scores > threshold)
         total <- length(scores)
         percent_above <- (count_above / total) * 100
         percent_above
       }
     #+end_src

  3. Choose the arguments: =scores= (the data vector) and =threshold= (the
     cutoff) are variable.
     #+begin_src R :session *R* :results output :exports both
       scores <- c(65, 78, 92, 55, 88)
       threshold <- 70
     #+end_src

  4. Make specific variable names more general: The definitions in the
     code are replaced by arguments. The variables will now be passed
     as arguments from the calling function, and the =result= will be
     returned.

     #+begin_src R :session *R* :results none
       ## Calculate percentage of values above threshold
       percent_above <- function(scores, threshold) {
         ##scores <- c(65, 78, 92, 55, 88)
         ##threshold <- 70
         count_above <- sum(scores > threshold)
         total <- length(scores)
         result <- (count_above / total) * 100
         return (result)
       }
     #+end_src

  5. Remove a final assignment: =result= can be removed, and the
     calculation can be returned directly:

     #+begin_src R :session *R* :results none
       ## Calculate percentage of values above threshold
       percent_above <- function(scores, threshold) {
         count_above <- sum(scores > threshold)
         total <- length(scores)
         (count_above / total) * 100
       }
     #+end_src

- Final code with sample data test:

  #+begin_src R :session *R* :results output :exports both
    ## function definition
    percent_above <- function(scores, threshold) {
      count_above <- sum(scores > threshold)
      total <- length(scores)
      (count_above / total) * 100
    }
    ## test
    scores <- c(65, 78, 92, 55, 88)
    threshold <- 70
    percent_above(scores, threshold)
  #+end_src

  #+RESULTS:
  : [1] 60

* Converting Tidyverse to Base R

This exercise provides a simple Tidyverse code snippet for students to
rewrite using only base R functions. The task involves reading a CSV
file, selecting specific columns, and filtering rows based on a
condition.

** Tidyverse Version
#+begin_src R :session *R* :results output :exports both
  library(dplyr)
  library(readr)
  
  process_grades <- function(filename) {
    grades <- read_csv(filename)
    grades %>%
      select(student_id, grade) %>%
      filter(grade >= 80)
  }
  
  process_grades("../data/grades.csv")
#+end_src

#+RESULTS:
#+begin_example
indexed 0B in  0s, 0B/sindexed 1.00TB in  0s, 2.10PB/s                                                                                        Rows: 4 Columns: 3
── Column specification ──────────────────────────────────────────────────────────────────
Delimiter: ","
chr (1): name
dbl (2): student_id, grade

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
# A tibble: 2 × 2
  student_id grade
       <dbl> <dbl>
1          1    85
2          3    90
#+end_example

- *Sample Data (grades.csv)*:
  #+begin_example
  student_id,name,grade
  1,Alice,85
  2,Bob,75
  3,Charlie,90
  4,David,65
  #+end_example

** Task
Rewrite the Tidyverse code above using only base R functions (no
external packages). Your solution should:
- Read the CSV file.
- Select the ~student_id~ and ~grade~ columns.
- Filter to keep only rows where ~grade~ is 80 or higher.
- Return the resulting data frame.

** Base R Solution (For Students to Fill In)
#+begin_src R :session *R* :results output :exports both
  process_grades_base <- function(filename) {
    # Your code here
  }
  
  process_grades_base("../data/grades.csv")
#+end_src

** Hints
- Use ~read.csv()~ instead of ~read_csv()~.
- Use column indexing (e.g., ~data[, c("col1", "col2")]~) instead of ~select()~.
- Use logical indexing (e.g., ~data[data$col > value, ]~) instead of
  ~filter()~.

** Expected Output
#+begin_example
  student_id grade
1          1    85
3          3    90
#+end_example

** Sample solution

#+begin_src R :session *R* :results output :exports both
  process_grades_base <- function(filename) {
    grades <- read.csv(filename)
    grades <- grades[, c("student_id", "grade")]
    grades[grades$grade >= 80, ]
  }
  
  process_grades_base("../data/grades.csv")
#+end_src

#+RESULTS:
: student_id grade
: 1          1    85
: 3          3    90

Note: You might get this warning if your CSV file does not end with a
new line.
#+begin_example
Warning message:
In read.table(file = file, header = header, sep = sep, quote = quote,  :
  incomplete final line found by readTableHeader on '../data/grades.csv'
#+end_example
